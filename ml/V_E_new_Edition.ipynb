{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SurajWijewickrama/auto-mesh/blob/main/ml/V_E_new_Edition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bkxQrNjcPkB",
        "outputId": "41d09a01-0ac5-4b60-9339-510ed8bebfb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.4.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.5)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install dgl torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torch-geometric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX-VdRuHcmZ4",
        "outputId": "0a865cf0-fabf-4fbb-8e92-6e49a01d9569"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import DataLoader  # Import the correct DataLoader\n",
        "from torch_geometric.data import Batch\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "tPEZx9w7cofR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SdTJ_N1XGHV",
        "outputId": "e7a01182-eccf-4673-e1f7-f6001c4cbde1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "import os\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "# Function to load JSON 3D objects as graphs\n",
        "def load_graph_data(folder_path):\n",
        "    data_list = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.json'):\n",
        "            with open(os.path.join(folder_path, filename)) as f:\n",
        "                graph_data = json.load(f)\n",
        "                x = torch.tensor(graph_data['v'], dtype=torch.float)  # Nodes' coordinates\n",
        "                edge_index = torch.tensor(graph_data['e'], dtype=torch.long).t().contiguous()  # Edge indices\n",
        "                data_list.append(Data(x=x, edge_index=edge_index))\n",
        "    return data_list\n",
        "\n",
        "# Specify the path where JSON files are located\n",
        "data_list = load_graph_data('/content/json')\n",
        "loader = DataLoader(data_list, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "msg-cdUrcq3Z",
        "outputId": "bbbbfaa0-8b8e-4cec-a195-1864824d363a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-220f58d83f71>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Specify the path where JSON files are located\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-220f58d83f71>\u001b[0m in \u001b[0;36mload_graph_data\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_graph_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# Load BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to convert text to embeddings\n",
        "def get_text_embedding(prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = bert_model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1)  # Get mean-pooled embeddings\n"
      ],
      "metadata": {
        "id": "K7mppfJzdCVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pUl-A8FQk7tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, VGAE\n",
        "\n",
        "class GraphEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GraphEncoder, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
        "        self.conv2 = GCNConv(2 * out_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "class VGAEWithEdgePrediction(VGAE):\n",
        "    def __init__(self, encoder, text_dim, latent_dim):\n",
        "        super(VGAEWithEdgePrediction, self).__init__(encoder)\n",
        "        self.fc1 = nn.Linear(text_dim, latent_dim)\n",
        "\n",
        "    def forward(self, x, edge_index, text_embedding):\n",
        "        z = self.encoder(x, edge_index)\n",
        "        z += self.fc1(text_embedding)  # Condition on text embeddings\n",
        "        return self.decode(z, edge_index), z  # Decode edges\n",
        "\n",
        "encoder = GraphEncoder(in_channels=3, out_channels=16)  # 3 for 3D coordinates\n",
        "model = VGAEWithEdgePrediction(encoder, text_dim=768, latent_dim=16)\n"
      ],
      "metadata": {
        "id": "dGsznaDhdGRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "epochs = 50\n",
        "\n",
        "def train(loader, prompt):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    text_embedding = get_text_embedding(prompt).to(device)\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon, z = model(data.x, data.edge_index, text_embedding)\n",
        "        loss = model.recon_loss(recon, data.edge_index) + (1 / data.num_nodes) * model.kl_loss()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "# Example usage with text prompt\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "bert_model = bert_model.to(device)\n",
        "\n",
        "prompt = \"Generate a low-poly tree model.\"\n",
        "for epoch in range(epochs):\n",
        "    loss = train(loader, prompt)\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss:.4f}')\n"
      ],
      "metadata": {
        "id": "_bxz3VRsdMAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAEEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super(VAEEncoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        mu = self.fc_mu(h1)\n",
        "        logvar = self.fc_logvar(h1)\n",
        "        return mu, logvar\n",
        "\n",
        "def reparameterize(mu, logvar):\n",
        "    std = torch.exp(0.5 * logvar)\n",
        "    eps = torch.randn_like(std)\n",
        "    return mu + eps * std\n"
      ],
      "metadata": {
        "id": "q_xiGkpVdOdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextConditionedGNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(TextConditionedGNN, self).__init__()\n",
        "        self.conv1 = GCNConv(800, 16)  # Concatenate text embedding\n",
        "        self.conv2_v = GCNConv(16, 3)      # Vertex output\n",
        "        self.conv2_e = GCNConv(16, 2)      # Edge presence output\n",
        "\n",
        "    def forward(self, x, edge_index, text_embedding):\n",
        "\n",
        "        num_nodes = x.size(0)\n",
        "        text_embedding_repeated = text_embedding.repeat_interleave(num_nodes // text_embedding.size(0), dim=0)\n",
        "        remainder = num_nodes % text_embedding.size(0)\n",
        "        if remainder > 0:\n",
        "            text_embedding_repeated = torch.cat([text_embedding_repeated, text_embedding[:remainder]], dim=0)\n",
        "        x = torch.cat([x, text_embedding_repeated], dim=1)\n",
        "\n",
        "        print(\"Shape of x before conv1:\", x.shape)\n",
        "\n",
        "\n",
        "\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        print(\"hiii\" ,x.shape)\n",
        "        vertices = self.conv2_v(x, edge_index)\n",
        "        edges = torch.sigmoid(self.conv2_e(x, edge_index))\n",
        "        print(\"Shape of vertices after concatenation:\", vertices.shape)\n",
        "        print(\"Shape of edges after concatenation:\", edges.shape)\n",
        "\n",
        "\n",
        "        return vertices, edges"
      ],
      "metadata": {
        "id": "-qYVzwA9djZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE-GNN Model\n",
        "class VAENet(nn.Module):\n",
        "    def __init__(self, encoder, gnn_decoder):\n",
        "        super(VAENet, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.gnn_decoder = gnn_decoder\n",
        "\n",
        "    def forward(self, x, edge_index, text_embedding):\n",
        "        mu, logvar = self.encoder(x)\n",
        "        z = reparameterize(mu, logvar)\n",
        "        vertices, edges = self.gnn_decoder(z, edge_index, text_embedding)\n",
        "        return vertices, edges, mu, logvar\n",
        "\n",
        "# Loss function for VAE\n",
        "def loss_function(recon_vertices, recon_edges, vertices, edges, mu, logvar,edge_index):\n",
        "    recon_edges = recon_edges.view(-1, recon_edges.shape[-1])\n",
        "    recon_edges_for_actual_edges = recon_edges[edge_index[0], edge_index[1] % recon_edges.shape[1]]\n",
        "     # Calculate loss using probabilities of only existing edges and ground truth labels\n",
        "    recon_loss = F.mse_loss(recon_vertices, vertices) + \\\n",
        "                 F.binary_cross_entropy(recon_edges_for_actual_edges, edges.view(-1))\n",
        "\n",
        "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + kld"
      ],
      "metadata": {
        "id": "nZ9CCuZkfB05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialize Model\n",
        "print(f\"Vertices shape: {batch.x.shape}\")\n",
        "print(f\"Edge index shape: {batch.edge_index.shape}\")\n",
        "print(f\"Text embedding shape: {batch.name_embedding.shape}\")\n",
        "\n",
        "encoder = VAEEncoder(input_dim=3 , hidden_dim=64, latent_dim=32)\n",
        "print(encoder.fc1)\n",
        "print(encoder.fc_mu)\n",
        "print(encoder.fc_logvar)\n",
        "text_embedding_dim = batch.name_embedding.shape[1]\n",
        "print(text_embedding_dim) # Get the actual dimension\n",
        "gnn_decoder = TextConditionedGNN()\n",
        "print(gnn_decoder.conv1)\n",
        "print(gnn_decoder.conv2_v)\n",
        "print(gnn_decoder.conv2_e)\n",
        "model = VAENet(encoder, gnn_decoder)\n",
        "print(model.encoder)\n",
        "print(model.gnn_decoder)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "data_loader = DataLoader(data_list, batch_size=2, shuffle=True)\n"
      ],
      "metadata": {
        "id": "-2D8K9LigCXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "    total_loss = 0\n",
        "    for batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        vertices, edges, mu, logvar = model(batch.x, batch.edge_index, batch.name_embedding)\n",
        "        loss = loss_function(vertices, edges, batch.x, batch.edge_label, mu, logvar,batch.edge_index)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}, Loss: {total_loss / len(data_loader)}')"
      ],
      "metadata": {
        "id": "5LZPYe49gFqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv  # Using Graph Convolutional Network as an example\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        # Encoder\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc_mu = nn.Linear(64, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(64, latent_dim)\n",
        "\n",
        "        # Decoder (for vertices and edges prediction)\n",
        "        self.decoder = nn.Linear(latent_dim, 128)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        h2 = F.relu(self.fc2(h1))\n",
        "        return self.fc_mu(h2), self.fc_logvar(h2)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decoder(z), mu, logvar\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0k_A213igIoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim, vertex_dim, edge_dim):\n",
        "        super(GNNDecoder, self).__init__()\n",
        "        self.conv1 = GCNConv(latent_dim, 64)\n",
        "        self.conv2 = GCNConv(64, vertex_dim)  # Output for vertex predictions\n",
        "\n",
        "        # Edge prediction\n",
        "        self.edge_fc = nn.Linear(64 * 2, edge_dim)  # Output dimension for edge predictions\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Vertex prediction\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        vertices_pred = self.conv2(x, edge_index)\n",
        "\n",
        "        # Edge prediction\n",
        "        row, col = edge_index\n",
        "        edge_features = torch.cat([x[row], x[col]], dim=1)  # Concatenate features of node pairs\n",
        "        edges_pred = self.edge_fc(edge_features)  # Predict edges between node pairs\n",
        "\n",
        "        return vertices_pred, edges_pred\n",
        "\n",
        "class VAE_GNN(nn.Module):\n",
        "    def __init__(self, vae_input_dim, latent_dim, vertex_dim, edge_dim):\n",
        "        super(VAE_GNN, self).__init__()\n",
        "        self.vae = VAE(vae_input_dim, latent_dim)\n",
        "        self.gnn = GNNDecoder(latent_dim, vertex_dim, edge_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        latent, mu, logvar = self.vae(x)\n",
        "        vertices_pred, edges_pred = self.gnn(latent, edge_index)\n",
        "        return vertices_pred, edges_pred, mu, logvar\n"
      ],
      "metadata": {
        "id": "PTu0AmcbxjYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def edge_loss(pred, target):\n",
        "    return F.binary_cross_entropy_with_logits(pred, target)\n",
        "\n",
        "def combined_loss(vertices_pred, vertices_true, edges_pred, edges_true, mu, logvar):\n",
        "    vertex_loss = F.mse_loss(vertices_pred, vertices_true, reduction='sum')\n",
        "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    edge_loss_value = edge_loss(edges_pred, edges_true)\n",
        "    return vertex_loss + kl_divergence + edge_loss_value\n",
        "\n",
        "def train(model, data_loader):\n",
        "    model.train()\n",
        "    for data in data_loader:  # Each data contains name embeddings, vertices, edges, and edge_index\n",
        "        name_embeddings, vertices, edges, edge_index = data\n",
        "        optimizer.zero_grad()\n",
        "        vertices_pred, edges_pred, mu, logvar = model(name_embeddings, edge_index)\n",
        "        loss = combined_loss(vertices_pred, vertices, edges_pred, edges, mu, logvar)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def infer(model, name, edge_index):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        name_embedding = embed_name(name)\n",
        "        vertices_pred, edges_pred, _, _ = model(name_embedding, edge_index)\n",
        "        return vertices_pred, edges_pred\n"
      ],
      "metadata": {
        "id": "XnQoPuQOxx_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UdND0feex665"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}